{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c816cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, Model\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import tensorflow.keras.backend as K\n",
    "import qkeras\n",
    "from qkeras import *\n",
    "\n",
    "# max number of jet constituents\n",
    "N = 32\n",
    "\n",
    "with h5py.File('data.h5', 'r') as f:\n",
    "    x = f['x'][:, :N, :]\n",
    "    y = f['y'][:]\n",
    "\n",
    "# min pt cut on jet constituents\n",
    "x[x[:, :, 0] < 2] = 0\n",
    "\n",
    "non_zero_counts = np.sum(np.any(x == 0, axis=(2)), axis=1)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(non_zero_counts, bins=range(0, N+2), edgecolor='black', alpha=0.5)\n",
    "plt.xlabel(f\"Number of zero-padded constituents per jet (max {N} constituents considered per jet)\")\n",
    "plt.ylabel(\"Count of jets\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "# normalization of the pt feature by interquantile range\n",
    "q5 = np.percentile(x[:, :, 0], 5)\n",
    "q95 = np.percentile(x[:, :, 0], 95)\n",
    "x[:, :, 0] = (x[:, :, 0] - 0) / (q95 - q5)\n",
    "\n",
    "train_ratio = 0.3\n",
    "val_ratio = 0.1\n",
    "test_ratio = 1 - train_ratio - val_ratio\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(x, y, test_size = test_ratio, random_state = 42)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size = val_ratio/(val_ratio + train_ratio), random_state = 42)\n",
    "print('X_train shape: ' + str(X_train.shape))\n",
    "print('X_val   shape: ' + str(X_val.shape))\n",
    "print('X_test  shape: ' + str(X_test.shape))\n",
    "print('Y_train shape: ' + str(Y_train.shape))\n",
    "print('Y_val   shape: ' + str(Y_val.shape))\n",
    "print('Y_test  shape: ' + str(Y_test.shape))\n",
    "del X_train_val, Y_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebced31",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_dim = 32\n",
    "rho_dim = 32\n",
    "\n",
    "def build_phi():\n",
    "    input_constituent = layers.Input(shape=(N, 3), name='phi_input')\n",
    "    x = QDense(phi_dim, activation='relu', use_bias=True, name='phi1',\n",
    "               kernel_quantizer=quantized_bits(8, 0, alpha=1.0),\n",
    "               bias_quantizer=quantized_bits(8, 0, alpha=1.0))(input_constituent)\n",
    "    \n",
    "    x = QDense(phi_dim, activation='relu', use_bias=True, name='phi2',\n",
    "               kernel_quantizer=quantized_bits(8, 0, alpha=1.0),\n",
    "               bias_quantizer=quantized_bits(8, 0, alpha=1.0))(x)\n",
    "    \n",
    "    x = QDense(phi_dim, activation='relu', use_bias=True, name='phi3',\n",
    "               kernel_quantizer=quantized_bits(8, 0, alpha=1.0),\n",
    "               bias_quantizer=quantized_bits(8, 0, alpha=1.0))(x)\n",
    "    \n",
    "    return models.Model(input_constituent, x, name=\"phi\")\n",
    "\n",
    "def build_phi_pointwiseConv1d():\n",
    "    quantizer = quantized_bits(10, 0, alpha=1)\n",
    "    quantized_relu = 'quantized_relu(10, 0)'\n",
    "    # Conv1D treats this as a 1D sequence with a length of N, and 3 channels.\n",
    "    input_constituent = layers.Input(shape=(N, 3), name='phi_input')\n",
    "    #input_constituent = QActivation('quantized_relu(8, 0)')(input_constituent)\n",
    "    \n",
    "    x = QConv1D(filters=phi_dim, kernel_size=1, use_bias=True, name='phi1')(input_constituent)\n",
    "    x = QActivation(quantized_relu, name='relu1')(x)\n",
    "    \n",
    "    x = QConv1D(filters=phi_dim, kernel_size=1, use_bias=True, name='phi2', kernel_quantizer=quantizer, bias_quantizer=quantizer)(x)\n",
    "    x = QActivation(quantized_relu, name='relu2')(x)\n",
    "    \n",
    "    x = QConv1D(filters=phi_dim, kernel_size=1, use_bias=True, name='phi3', kernel_quantizer=quantizer, bias_quantizer=quantizer)(x)\n",
    "    x = QActivation(quantized_relu, name='relu3')(x)\n",
    "    \n",
    "    return models.Model(input_constituent, x, name=\"phi\")\n",
    "\n",
    "def build_rho():\n",
    "    quantizer = quantized_bits(10, 0, alpha=1)\n",
    "    quantized_relu = 'quantized_relu(10, 0)'\n",
    "    input_agg = layers.Input(shape=(phi_dim,), name='rho_input')\n",
    "    \n",
    "    x = QDense(rho_dim, use_bias=True, name='rho1', kernel_quantizer=quantizer, bias_quantizer=quantizer)(input_agg)\n",
    "    x = QActivation(quantized_relu, name='relu4')(x)\n",
    "    \n",
    "    x = QDense(5, use_bias=True, name='rho2', kernel_quantizer=quantizer, bias_quantizer=quantizer)(x)\n",
    "    x = QActivation('softmax', name='softmax')(x)\n",
    "    \n",
    "    return models.Model(input_agg, x, name=\"rho\")\n",
    "\n",
    "#phi = build_phi()\n",
    "phi = build_phi_pointwiseConv1d()\n",
    "rho = build_rho()\n",
    "\n",
    "input_constituent = layers.Input(shape=(N, 3))\n",
    "phi_output = phi(input_constituent)\n",
    "agg = layers.GlobalMaxPooling1D()(phi_output)\n",
    "rho_output = rho(agg)\n",
    "\n",
    "model = models.Model(input_constituent, rho_output)\n",
    "\n",
    "#phi.summary()\n",
    "#rho.summary()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.008),\n",
    "              loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b4fb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    validation_data = (X_val, Y_val),\n",
    "                    epochs=20, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0e151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['loss'], label = 'train loss')\n",
    "axes.plot(history.history['val_loss'], label = 'val loss')\n",
    "axes.legend(loc = \"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0c1ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(np.argmax(Y_test, axis=1), np.argmax(Y_pred, axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef090e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(y_test, y_pred, labels):\n",
    "    for x, label in enumerate(labels):        \n",
    "        fpr, tpr, _ = roc_curve(y_test[:, x], y_pred[:, x])\n",
    "        plt.plot(fpr, tpr, label='{0} tagger, AUC = {1:.1f}'.format(label, auc(fpr, tpr)*100.), linestyle='-')\n",
    "    #plt.semilogy()\n",
    "    #plt.semilogx()\n",
    "    plt.ylabel(\"Signal Efficiency\")\n",
    "    plt.xlabel(\"Background Efficiency\")\n",
    "    #plt.ylim(0.00001, 1)\n",
    "    #plt.xlim(0.00001, 1)\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='best')  \n",
    "    \n",
    "plt.figure(figsize=(4, 4))\n",
    "plot_roc(Y_test, Y_pred, ['g','q','w','z','t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6304626e-27ff-4725-af99-1bad28fa200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baa3f67-f8c3-44c3-913e-370d64ecbc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a9aab3-bc83-43e7-8a97-8e6ada8abd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c14bb1-9613-47a8-9fa6-d472a339257a",
   "metadata": {},
   "source": [
    "# HLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1132b311-1fab-4e96-ad91-b6423c3c3077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "import qkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d11d78-ecc6-4c50-94c2-1a9796b397b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.converters.convert_from_keras_model(model,\n",
    "                                           output_dir='my-hls-test',\n",
    "                                           project_name='myproject',\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3b7fab-db65-4e61-946d-13c1c1d2f27f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6101b047-6d93-413c-9361-40c8124f9b97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2427e244-1b99-4672-87f4-c8ce09ee7505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da09384-6557-401c-a756-ec0c2282ffa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6974e47b-4c7d-4e5f-8857-deeaa0d572b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d7f4ca-eae3-449f-a5c2-4454fa8e8b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f85a93-15c0-4a9e-9e2f-7237e10a4522",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_layer = model.get_layer('time_distributed').layer\n",
    "X_test_mask = layers.Masking(mask_value=0.)(X_test)\n",
    "phi_outputs_mask = layers.TimeDistributed(phi_layer)(X_test_mask)\n",
    "agg_mask = model.layers[2](phi_outputs_mask)\n",
    "Y_pred_mask = model.layers[3](agg_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083efdaa-c6d5-49eb-8a4c-bee9f0fa962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {}\".format(accuracy_score(np.argmax(Y_test, axis=1), np.argmax(Y_pred, axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9ce86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {}\".format(accuracy_score(np.argmax(Y_test, axis=1), np.argmax(Y_pred_mask, axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf613572-48ab-4cc9-bde8-93b3abddc408",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742e0966-8fdb-43be-b920-c7741d3667d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ecd1b9-d549-4914-aa23-9a8e63487eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bee108-c46f-49da-be23-daac7d065ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
