{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c816cda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: Unable to import optimizer(s) from expr_templates.py: No module named 'sympy'\n",
      "WARNING: Failed to import handlers from merge.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from convolution.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from recurrent.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from reshape.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from pooling.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from core.py: No module named 'torch'.\n",
      "X_train.shape: (60000, 10, 10, 1)\n",
      "Y_train.shape: (60000, 10)\n",
      "X_test.shape: (10000, 10, 10, 1)\n",
      "Y_test.shape: (10000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hofungtsoi/miniforge3/envs/sparse/lib/python3.10/site-packages/hls4ml/converters/__init__.py:28: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, Model\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import tensorflow.keras.backend as K\n",
    "import qkeras\n",
    "from qkeras import *\n",
    "import hls4ml\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = keras.datasets.mnist.load_data()\n",
    "X_train = np.reshape(X_train[:, :10, :10], (X_train.shape[0], 10, 10, 1)) / 255.\n",
    "X_test = np.reshape(X_test[:, :10, :10], (X_test.shape[0], 10, 10, 1)) / 255.\n",
    "\n",
    "def select_classes(x, y, classes):\n",
    "    idx = (y == 99)\n",
    "    for i in range(len(classes)):\n",
    "        idx |= (y == classes[i])\n",
    "    x, y = x[idx], y[idx]\n",
    "    return x, y\n",
    "\n",
    "classes = [0,1,2,3,4,5,6,7,8,9]\n",
    "X_train, Y_train = select_classes(X_train, Y_train, classes)\n",
    "X_test, Y_test = select_classes(X_test, Y_test, classes)\n",
    "\n",
    "LE = LabelEncoder()\n",
    "Y_train = LE.fit_transform(Y_train)\n",
    "Y_test = LE.fit_transform(Y_test)\n",
    "\n",
    "Y_train = to_categorical(Y_train, len(classes))\n",
    "Y_test = to_categorical(Y_test, len(classes))\n",
    "\n",
    "#X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "#X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "\n",
    "print(\"X_train.shape: \" + str(X_train.shape))\n",
    "print(\"Y_train.shape: \" + str(Y_train.shape))\n",
    "print(\"X_test.shape: \" + str(X_test.shape))\n",
    "print(\"Y_test.shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbe7c08e-06b0-44b4-9b63-45ed32742d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " x_in (InputLayer)           [(None, 50, 40, 1)]       0         \n",
      "                                                                 \n",
      " conv1 (QConv2D)             (None, 50, 40, 1)         9         \n",
      "                                                                 \n",
      " relu1 (QActivation)         (None, 50, 40, 1)         0         \n",
      "                                                                 \n",
      " pool1 (AveragePooling2D)    (None, 25, 20, 1)         0         \n",
      "                                                                 \n",
      " conv2 (QConv2D)             (None, 25, 20, 1)         9         \n",
      "                                                                 \n",
      " relu2 (QActivation)         (None, 25, 20, 1)         0         \n",
      "                                                                 \n",
      " pool2 (AveragePooling2D)    (None, 5, 4, 1)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 20)                0         \n",
      "                                                                 \n",
      " dense1 (QDense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39 (156.00 Byte)\n",
      "Trainable params: 39 (156.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "quantizer = quantized_bits(16, 6, alpha=1)\n",
    "quantized_relu = 'quantized_relu(16, 6)'\n",
    "\n",
    "x_in = keras.Input(shape=(50, 40, 1), name='x_in')\n",
    "\n",
    "x = QConv2D(filters=1, kernel_size=(3, 3), use_bias=False, name='conv1',\n",
    "            padding='same', strides=1,\n",
    "            kernel_quantizer=quantizer, bias_quantizer=quantizer)(x_in)\n",
    "x = QActivation(quantized_relu, name='relu1')(x)\n",
    "x = layers.AveragePooling2D(2, name='pool1')(x)\n",
    "\n",
    "x = QConv2D(filters=1, kernel_size=(3, 3), use_bias=False, name='conv2',\n",
    "            padding='same', strides=1,\n",
    "            kernel_quantizer=quantizer, bias_quantizer=quantizer)(x)\n",
    "x = QActivation(quantized_relu, name='relu2')(x)\n",
    "x = layers.AveragePooling2D(5, name='pool2')(x)\n",
    "\n",
    "x = layers.Flatten(name='flatten')(x)\n",
    "\n",
    "x = QDense(1, kernel_quantizer=quantizer, bias_quantizer=quantizer, name='dense1')(x)\n",
    "    \n",
    "#x = QConv2D(filters=1, kernel_size=(3, 3), use_bias=False, name='conv2',\n",
    "#            padding='same', strides=1,\n",
    "#            kernel_quantizer=quantizer, bias_quantizer=quantizer)(x)\n",
    "#x = QActivation(quantized_relu, name='relu2')(x)\n",
    "\n",
    "model = keras.Model(x_in, x, name='test_model')\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.005),\n",
    "              loss='mse', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b4fb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, X_train,\n",
    "                    #validation_data = (X_val, X_val),\n",
    "                    epochs=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0e151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['loss'], label = 'train loss')\n",
    "axes.plot(history.history['val_loss'], label = 'val loss')\n",
    "axes.legend(loc = \"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0c1ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(np.argmax(Y_test, axis=1), np.argmax(Y_pred, axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef090e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(y_test, y_pred, labels):\n",
    "    for x, label in enumerate(labels):        \n",
    "        fpr, tpr, _ = roc_curve(y_test[:, x], y_pred[:, x])\n",
    "        plt.plot(fpr, tpr, label='{0} tagger, AUC = {1:.1f}'.format(label, auc(fpr, tpr)*100.), linestyle='-')\n",
    "    #plt.semilogy()\n",
    "    #plt.semilogx()\n",
    "    plt.ylabel(\"Signal Efficiency\")\n",
    "    plt.xlabel(\"Background Efficiency\")\n",
    "    #plt.ylim(0.00001, 1)\n",
    "    #plt.xlim(0.00001, 1)\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='best')  \n",
    "    \n",
    "plt.figure(figsize=(4, 4))\n",
    "plot_roc(Y_test, Y_pred, ['g','q','w','z','t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6304626e-27ff-4725-af99-1bad28fa200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baa3f67-f8c3-44c3-913e-370d64ecbc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = qkeras.utils.load_qmodel('model_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a9aab3-bc83-43e7-8a97-8e6ada8abd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c14bb1-9613-47a8-9fa6-d472a339257a",
   "metadata": {},
   "source": [
    "# HLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81d11d78-ecc6-4c50-94c2-1a9796b397b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: x_in, layer type: InputLayer, input shapes: [[None, 50, 40, 1]], output shape: [None, 50, 40, 1]\n",
      "Layer name: conv1, layer type: QConv2D, input shapes: [[None, 50, 40, 1]], output shape: [None, 50, 40, 1]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 50, 40, 1]], output shape: [None, 50, 40, 1]\n",
      "Layer name: pool1, layer type: AveragePooling2D, input shapes: [[None, 50, 40, 1]], output shape: [None, 25, 20, 1]\n",
      "Layer name: conv2, layer type: QConv2D, input shapes: [[None, 25, 20, 1]], output shape: [None, 25, 20, 1]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 25, 20, 1]], output shape: [None, 25, 20, 1]\n",
      "Layer name: pool2, layer type: AveragePooling2D, input shapes: [[None, 25, 20, 1]], output shape: [None, 5, 4, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 5, 4, 1]], output shape: [None, 20]\n",
      "Layer name: dense1, layer type: QDense, input shapes: [[None, 20]], output shape: [None, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hofungtsoi/miniforge3/envs/sparse/lib/python3.10/site-packages/keras/src/constraints.py:365: UserWarning: The `keras.constraints.serialize()` API should only be used for objects of type `keras.constraints.Constraint`. Found an instance of type <class 'qkeras.quantizers.quantized_bits'>, which may lead to improper serialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': {'Precision': {'default': 'fixed<16,6>'},\n",
       "  'ReuseFactor': 1,\n",
       "  'Strategy': 'Latency',\n",
       "  'BramFactor': 1000000000,\n",
       "  'TraceOutput': False},\n",
       " 'LayerName': {'x_in': {'Trace': False,\n",
       "   'Precision': 'ap_fixed<12, 4, AP_RND, AP_SAT>'},\n",
       "  'conv1': {'Trace': False,\n",
       "   'Precision': {'result': 'auto',\n",
       "    'weight': 'fixed<16,7,TRN,WRAP,0>',\n",
       "    'bias': 'fixed<16,7,TRN,WRAP,0>'},\n",
       "   'ParallelizationFactor': 20},\n",
       "  'conv1_linear': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'relu1': {'Trace': False,\n",
       "   'Precision': {'result': 'ufixed<16,6,RND_CONV,SAT,0>'}},\n",
       "  'pool1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'conv2': {'Trace': False,\n",
       "   'Precision': {'result': 'auto',\n",
       "    'weight': 'fixed<16,7,TRN,WRAP,0>',\n",
       "    'bias': 'fixed<16,7,TRN,WRAP,0>'},\n",
       "   'ParallelizationFactor': 5},\n",
       "  'conv2_linear': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'relu2': {'Trace': False,\n",
       "   'Precision': {'result': 'ufixed<16,6,RND_CONV,SAT,0>'}},\n",
       "  'pool2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'flatten': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'dense1': {'Trace': False,\n",
       "   'Precision': {'result': 'auto',\n",
       "    'weight': 'fixed<16,7,TRN,WRAP,0>',\n",
       "    'bias': 'fixed<16,7,TRN,WRAP,0>'}},\n",
       "  'dense1_linear': {'Trace': False, 'Precision': {'result': 'auto'}}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = tf.keras.models.load_model('model-pointwisePhi.keras')\n",
    "#model = tf.keras.models.load_model('model-densePhi.keras')\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "config['Model']['Strategy'] = 'Latency'\n",
    "config['LayerName']['x_in']['Precision'] = 'ap_fixed<12, 4, AP_RND, AP_SAT>'\n",
    "config['LayerName']['conv1']['ParallelizationFactor'] = 20\n",
    "\n",
    "config['LayerName']['conv2']['ParallelizationFactor'] = 5\n",
    "\n",
    "# for dense Phi\n",
    "if False:\n",
    "    config['LayerName']['phi1']['ParallelizationFactor'] = 1\n",
    "    config['LayerName']['phi1']['ReuseFactor'] = 8\n",
    "    config['LayerName']['phi1']['Strategy'] = 'Latency'\n",
    "    #config['LayerName']['phi1']['ConvImplementation'] = 'Pointwise'\n",
    "    \n",
    "    config['LayerName']['phi2']['ParallelizationFactor'] = 1\n",
    "    config['LayerName']['phi2']['ReuseFactor'] = 8\n",
    "    config['LayerName']['phi2']['Strategy'] = 'Latency'\n",
    "    #config['LayerName']['phi2']['ConvImplementation'] = 'Pointwise'\n",
    "    \n",
    "    config['LayerName']['phi3']['ParallelizationFactor'] = 1\n",
    "    config['LayerName']['phi3']['ReuseFactor'] = 8\n",
    "    config['LayerName']['phi3']['Strategy'] = 'Latency'\n",
    "    #config['LayerName']['phi3']['ConvImplementation'] = 'Pointwise'\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08c7756a-62b6-40af-8d86-04c694965727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: x_in, layer type: InputLayer, input shapes: [[None, 50, 40, 1]], output shape: [None, 50, 40, 1]\n",
      "Layer name: conv1, layer type: QConv2D, input shapes: [[None, 50, 40, 1]], output shape: [None, 50, 40, 1]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 50, 40, 1]], output shape: [None, 50, 40, 1]\n",
      "Layer name: pool1, layer type: AveragePooling2D, input shapes: [[None, 50, 40, 1]], output shape: [None, 25, 20, 1]\n",
      "Layer name: conv2, layer type: QConv2D, input shapes: [[None, 25, 20, 1]], output shape: [None, 25, 20, 1]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 25, 20, 1]], output shape: [None, 25, 20, 1]\n",
      "Layer name: pool2, layer type: AveragePooling2D, input shapes: [[None, 25, 20, 1]], output shape: [None, 5, 4, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 5, 4, 1]], output shape: [None, 20]\n",
      "Layer name: dense1, layer type: QDense, input shapes: [[None, 20]], output shape: [None, 1]\n",
      "Creating HLS model\n",
      "Writing HLS project\n",
      "Done\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    model,\n",
    "    hls_config=config,\n",
    "    project_name='model_test',\n",
    "    output_dir='model_test',\n",
    "    part='xcvu13p-flga2577-2-e',\n",
    "    io_type='io_parallel',\n",
    ")\n",
    "\n",
    "hls_model.compile()\n",
    "hls_model.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3b7fab-db65-4e61-946d-13c1c1d2f27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hls_pred = hls_model.predict(X_test)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(np.argmax(Y_test, axis=1), np.argmax(Y_hls_pred, axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2427e244-1b99-4672-87f4-c8ce09ee7505",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plot_roc(Y_test, Y_hls_pred, ['g','q','w','z','t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da09384-6557-401c-a756-ec0c2282ffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del hls_model, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d7f4ca-eae3-449f-a5c2-4454fa8e8b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3d8d7fc-064b-47b9-9588-b49ce41cc72c",
   "metadata": {},
   "source": [
    "# test bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c41fd1-263f-4951-bdf0-5de6974b2f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3437ac33-296e-4b88-89a1-315203103a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "arr = np.zeros((3, 50, 40, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2c6405f-de5e-4500-92e5-6b76e55b31fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[0, 3, 3, 0] = 1\n",
    "arr[0, 4, 8, 0] = 2\n",
    "arr[0, 7, 4, 0] = 3\n",
    "\n",
    "arr[1, 4, 4, 0] = 1\n",
    "arr[1, 4, 5, 0] = 2\n",
    "arr[1, 2, 8, 0] = 3\n",
    "arr[1, 3, 8, 0] = 4\n",
    "arr[1, 5, 8, 0] = 5\n",
    "\n",
    "arr[2, 4, 4, 0] = 1\n",
    "arr[2, 5, 4, 0] = 2\n",
    "arr[2, 6, 4, 0] = 3\n",
    "arr[2, 3, 5, 0] = 4\n",
    "arr[2, 2, 5, 0] = 5\n",
    "arr[2, 5, 8, 0] = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "344713bd-e25f-46b3-bfd3-d6ce6d32df57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ 1 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ 2 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ 3 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ 3 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ 4 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ 1 2 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ 5 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ 5 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ 4 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ 1 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ 2 _ _ _ 6 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ 3 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(3):\n",
    "  for i in range(50):\n",
    "      row = arr[k, i, :, 0]\n",
    "      row_str = ' '.join(\"_\" if val == 0 else f\"{val:1.0f}\" for val in row)\n",
    "      print(row_str)\n",
    "  print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3907c692-0a1c-468c-af01-b9de782d0c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_arr = model.predict(arr)\n",
    "Y_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be06041d-3956-4f4a-b21d-7ec0f571f7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hls_arr = hls_model.predict(arr)\n",
    "Y_hls_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2dcda30-9763-4edf-85ea-d787a96d4469",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_test/tb_data/tb_input_features.dat', 'w') as my_file:\n",
    "    for sample in arr.reshape(-1, np.prod(arr.shape[1:])):\n",
    "        my_file.write(' '.join(str(x) for x in sample))\n",
    "        my_file.write('\\n')\n",
    "\n",
    "with open('model_test/tb_data/tb_output_predictions.dat', 'w') as my_file:\n",
    "    for sample in arr.reshape(-1, np.prod(arr.shape[1:])):\n",
    "        my_file.write(' '.join(str(x) for x in sample))\n",
    "        my_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4324e054-014c-4e0e-b2d2-32e3b43ca9e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
